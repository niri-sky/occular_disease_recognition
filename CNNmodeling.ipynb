{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38f54474-6355-42b1-8c8d-a531822c58b1",
   "metadata": {},
   "source": [
    "## CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8746ce63-2a24-4ab9-af10-d5699cd6c006",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0953519-4400-4eb6-8063-e37a3922e47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2c89846-21e1-4313-9517-e6ee4f354058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663277fd-f709-4b4f-942f-ccd6373ac0b4",
   "metadata": {},
   "source": [
    "### Reading in image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db6d4ec-c214-496c-be6e-6a25634629d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in image data here. try a target size of 512x512 (that was what preprocessed images in one of the kaggle datasets had)\n",
    "# also normalize the data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f2fac2-07be-442d-ac28-d26b167e3ac4",
   "metadata": {},
   "source": [
    "### Setting X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b60244-1c3b-499d-80fd-6fd16ac66aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set X and y here\n",
    "\n",
    "# X will be the array of images\n",
    "# y will be the target. If y is multiclass instead of binary, use y = to_categorical(y) to one-hot-encode y in keras\n",
    "\n",
    "# images should already be scaled (normalized) so we don't need to use StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164e147d-db8f-41b7-b481-2bae672c7c55",
   "metadata": {},
   "source": [
    "### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943563d9-49f4-4888-8331-27f9407112a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776dd38a-1bde-4403-9502-33d18d2c2dc1",
   "metadata": {},
   "source": [
    "### Building the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baaeb65-65c3-417c-b882-56e3bc73d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a Sequential model (that will process each layer sequentially)\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207bcbf3-ec8f-4d3c-a8a8-2f9abc454857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a Convolutional 2D layer that will create 16 3x3 filters to detect image features\n",
    "\n",
    "# starting with a small number of features and increasing them for each layer is recommended because\n",
    "# the model finds the smaller number of main features first and then builds them up into more complex larger numbers of features\n",
    "\n",
    "# the input shape is 512x512 pixels with 3 channels (RGB)\n",
    "# one of the kaggle datasets with preprocessed images had processed them to a 512x512 size\n",
    "\n",
    "# using relu (rectified linear function) activation, which returns positive output directly and returns 0 for negative output\n",
    "\n",
    "model.add(Conv2D(16, (3,3), activation='relu', input_shape=(512,512,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2267b39c-9f9a-4740-b6dd-faccf985ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a MaxPooling 2D layer that will take the maximum value in every 2x2 grid (with a stride defaulting to the pool_size)\n",
    "# this effectively cuts the dimensions of the data in half, and helps get rid of noise caused by small variations in the image\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "476205ad-de18-4027-b8c5-0f180d94c004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add more convolutional layers (with max pooling between each one) \n",
    "\n",
    "# increasing filters to 32\n",
    "# input shape is only needed for the first layer above\n",
    "model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "\n",
    "# increasing filters to 64\n",
    "model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2dea11-4860-481f-8355-c9044640a48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a flatten layer to bridge between the convolutional layers and the dense layers\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbb87d6-f17c-4068-9020-45982992a2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dense layer analyzes the features that were identified in the convolutional layers \n",
    "model.add(Dense(256, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987b4e18-8c1b-4966-8901-0fe58b61f989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the output layer\n",
    "# if thre are multiple classes (not binary), change the nodes to the number of classes and use softmax activation\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f22ff4cb-96d0-49c3-b77b-a77f79804193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "# if multiclass, use categorical_crossentropy instead \n",
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61749c92-481b-44c0-b03c-1d799c0038fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the model and save it as h so the accuracy and loss scores for each epoch can be visualized\n",
    "# batch size is the number of images processed before updating the metrics\n",
    "# epochs is the number of times the model goes through the entire dataset\n",
    "h = model.fit(X_train, y_train, validation_data=(X_test,y_test), batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501cd77b-cb33-4491-88c5-87793dc81b46",
   "metadata": {},
   "source": [
    "### Visualizing the accuracy and loss scores for each epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb492adc-c09e-4464-a211-bef1b5847fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val accuracy')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282dc536-63e6-4681-a172-99bd2d4739fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h.history['loss'], label='training loss')\n",
    "plt.plot(h.history['val_loss'], label='validation loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89881109-f6a7-42d5-aa26-2b4a12977d70",
   "metadata": {},
   "source": [
    "### Feature Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30501b77-dbb0-4dab-9abe-2cb17460c369",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't need to do this but I found a blog about how to write code to see the feature maps generated by the model--\n",
    "# https://www.analyticsvidhya.com/blog/2020/11/tutorial-how-to-visualize-feature-maps-directly-from-cnn-layers/\n",
    "\n",
    "# if we have time it would be cool to try this"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
