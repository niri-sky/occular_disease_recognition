{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping with Beautiful Soup Lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libaries here\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "import html\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create a soup object from the home page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/'\n",
    "res = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "soup = BeautifulSoup(res.content, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Scrape the home page soup for every restaurant\n",
    "\n",
    "Note: Your best bet is to create a list of dictionaries, one for each restaurant. Each dictionary contains the restaurant's name and path from the `href`. The result of your scrape should look something like this:\n",
    "\n",
    "```python\n",
    "restaurants = [\n",
    "    {'name': 'A&W Restaurants', 'href': 'restaurants/1.html'}, \n",
    "    {'name': \"Applebee's\", 'href': 'restaurants/2.html'},\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find(class_='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurants = []\n",
    "for row in table.find_all('td'):\n",
    "    restaurant = {}\n",
    "    restaurant['name'] = row.find('a').text.strip()\n",
    "    restaurant['href'] = row.find('a').attrs['href']\n",
    "    restaurants.append(restaurant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'A&W Restaurants', 'href': 'restaurants/1.html'},\n",
       " {'name': \"Applebee's\", 'href': 'restaurants/2.html'},\n",
       " {'name': \"Arby's\", 'href': 'restaurants/3.html'},\n",
       " {'name': 'Atlanta Bread Company', 'href': 'restaurants/4.html'},\n",
       " {'name': \"Bojangle's Famous Chicken 'n Biscuits\",\n",
       "  'href': 'restaurants/5.html'},\n",
       " {'name': 'Buffalo Wild Wings', 'href': 'restaurants/6.html'},\n",
       " {'name': 'Burger King', 'href': 'restaurants/7.html'},\n",
       " {'name': \"Captain D's\", 'href': 'restaurants/8.html'},\n",
       " {'name': \"Carl's Jr.\", 'href': 'restaurants/9.html'},\n",
       " {'name': \"Charley's Grilled Subs\", 'href': 'restaurants/10.html'},\n",
       " {'name': 'Chick-fil-A', 'href': 'restaurants/11.html'},\n",
       " {'name': \"Chili's\", 'href': 'restaurants/12.html'},\n",
       " {'name': 'Chipotle Mexican Grill', 'href': 'restaurants/13.html'},\n",
       " {'name': \"Church's\", 'href': 'restaurants/14.html'},\n",
       " {'name': 'Corner Bakery Cafe', 'href': 'restaurants/15.html'},\n",
       " {'name': 'Dairy Queen', 'href': 'restaurants/16.html'},\n",
       " {'name': \"Denny's\", 'href': 'restaurants/17.html'},\n",
       " {'name': 'El Pollo Loco', 'href': 'restaurants/18.html'},\n",
       " {'name': 'FATZ', 'href': 'restaurants/19.html'},\n",
       " {'name': \"Fazoli's\", 'href': 'restaurants/20.html'},\n",
       " {'name': 'Five Guys Burgers and Fries', 'href': 'restaurants/21.html'},\n",
       " {'name': 'Golden Chick', 'href': 'restaurants/22.html'},\n",
       " {'name': \"Hardee's\", 'href': 'restaurants/23.html'},\n",
       " {'name': 'IHOP', 'href': 'restaurants/24.html'},\n",
       " {'name': 'In-N-Out Burger', 'href': 'restaurants/25.html'},\n",
       " {'name': 'Jack in the Box', 'href': 'restaurants/26.html'},\n",
       " {'name': 'Jimmy Johns', 'href': 'restaurants/27.html'},\n",
       " {'name': \"Joe's Crab Shack\", 'href': 'restaurants/28.html'},\n",
       " {'name': 'KFC', 'href': 'restaurants/29.html'},\n",
       " {'name': \"McDonald's\", 'href': 'restaurants/30.html'},\n",
       " {'name': \"O'Charley's\", 'href': 'restaurants/31.html'},\n",
       " {'name': 'Olive Garden', 'href': 'restaurants/32.html'},\n",
       " {'name': 'Outback Steakhouse', 'href': 'restaurants/33.html'},\n",
       " {'name': 'Panda Express', 'href': 'restaurants/34.html'},\n",
       " {'name': 'Panera Bread', 'href': 'restaurants/35.html'},\n",
       " {'name': \"Popeye's\", 'href': 'restaurants/36.html'},\n",
       " {'name': 'Quiznos', 'href': 'restaurants/37.html'},\n",
       " {'name': 'Red Robin Gourmet Burgers', 'href': 'restaurants/38.html'},\n",
       " {'name': \"Romano's Macaroni Grill\", 'href': 'restaurants/39.html'},\n",
       " {'name': 'Ruby Tuesday', 'href': 'restaurants/40.html'},\n",
       " {'name': 'Subway', 'href': 'restaurants/41.html'},\n",
       " {'name': 'Taco Bell', 'href': 'restaurants/42.html'},\n",
       " {'name': 'Taco Bueno', 'href': 'restaurants/43.html'},\n",
       " {'name': \"Wendy's\", 'href': 'restaurants/44.html'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Using the `href`, scrape each restaurant's page and create a single list of food dictionaries.\n",
    "\n",
    "Your list of foods should look something like this:\n",
    "```python\n",
    "foods = [\n",
    "    {\n",
    "        'calories': '0',\n",
    "        'carbs': '0',\n",
    "        'category': 'Drinks',\n",
    "        'fat': '0',\n",
    "        'name': 'A&W® Diet Root Beer',\n",
    "        'restaurant': 'A&W Restaurants'\n",
    "    },\n",
    "    {\n",
    "        'calories': '0',\n",
    "        'carbs': '0',\n",
    "        'category': 'Drinks',\n",
    "        'fat': '0',\n",
    "        'name': 'A&W® Diet Root Beer',\n",
    "        'restaurant': 'A&W Restaurants'\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "**Note**: Remove extra white space from each category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying manually for the first restaurant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "href = []\n",
    "for i in range(len(restaurants)):\n",
    "    href.append(restaurants[i]['href'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_r = []\n",
    "for i in range(len(restaurants)):\n",
    "    name_r.append(restaurants[i]['name'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/1.html'\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.content, 'lxml')\n",
    "table = soup.find_all('td') \n",
    "foods = []\n",
    "\n",
    "for i in table:\n",
    "    foods.append(i.text.strip())\n",
    "    \n",
    "# Breaking list into chunks:    \n",
    "chunks = [foods[x:x+5] for x in range(0, len(foods), 5)]\n",
    "list_keys = ['name', 'category', 'calories', 'fat', 'carbs', 'restaurant']\n",
    "\n",
    "\n",
    "for chunk in chunks:\n",
    "    chunk.append('A&W Restaurants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def as_dict_list(data: list, columns: list):\n",
    "    return [dict((zip(columns, row))) for row in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "menu1 = as_dict_list(chunks, list_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For other restaurants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_test = 'https://pages.git.generalassemb.ly/rldaggie/for-scraping/restaurants/{}.html'\n",
    "urls = []\n",
    "for i in range(1, len(href)):\n",
    "    urls.append(url_test.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in urls:\n",
    "    res = requests.get( url)\n",
    "    soup = BeautifulSoup(res.content, 'lxml')\n",
    "    table = soup.find_all('td')\n",
    "    foods = []\n",
    "\n",
    "    for i in table:\n",
    "        foods.append(i.text.strip())\n",
    "\n",
    "    # Breaking list into chunks:    \n",
    "    chunks = [foods[x:x+5] for x in range(0, len(foods), 5)]\n",
    "    list_keys = ['name', 'category', 'calories', 'fat', 'carbs', 'restaurant']\n",
    "\n",
    "    for name in name_r:\n",
    "        for chunk in chunks:\n",
    "            chunk.append(name)\n",
    "    \n",
    "menu_n = as_dict_list(chunks, list_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def menu(url, name):\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.content, 'lxml')\n",
    "    table = soup.find_all('td') \n",
    "    foods = []\n",
    "\n",
    "    for i in table:\n",
    "        foods.append(i.text.strip())\n",
    "\n",
    "    # Breaking list into chunks:    \n",
    "    chunks = [foods[x:x+5] for x in range(0, len(foods), 5)]\n",
    "    list_keys = ['name', 'category', 'calories', 'fat', 'carbs', 'restaurant']\n",
    "\n",
    "\n",
    "    for chunk in chunks:\n",
    "        chunk.append(name)\n",
    "        \n",
    "    menu = as_dict_list(chunks, list_keys)\n",
    "    return menu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#result = []\n",
    "\n",
    "#for url in urls:\n",
    "    #for name in name_r:\n",
    "        #result.append(menu(url, name))\n",
    "        \n",
    "my_list = list(zip(urls, name_r))       \n",
    "a = []\n",
    "for url, name in my_list:\n",
    "    a.append(menu(url, name))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(t):\n",
    "    return [item for sublist in t for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = flatten(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create a pandas DataFrame from your list of foods\n",
    "\n",
    "**Note**: Your DataFrame should have 5,131 rows. Please output the number of rows in your DataFrame!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>calories</th>\n",
       "      <th>fat</th>\n",
       "      <th>carbs</th>\n",
       "      <th>restaurant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Original Bacon Double Cheeseburger</th>\n",
       "      <td>Burgers</td>\n",
       "      <td>760</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>A&amp;W Restaurants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Coney (Chili) Dog</th>\n",
       "      <td>Entrees</td>\n",
       "      <td>340</td>\n",
       "      <td>20</td>\n",
       "      <td>26</td>\n",
       "      <td>A&amp;W Restaurants</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   category calories fat carbs  \\\n",
       "name                                                             \n",
       "Original Bacon Double Cheeseburger  Burgers      760  45    45   \n",
       "Coney (Chili) Dog                   Entrees      340  20    26   \n",
       "\n",
       "                                         restaurant  \n",
       "name                                                 \n",
       "Original Bacon Double Cheeseburger  A&W Restaurants  \n",
       "Coney (Chili) Dog                   A&W Restaurants  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(b)\n",
    "df = df.set_index('name')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5067, 5)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many rows does your dataframe have?\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Export to csv\n",
    "\n",
    "**Note:** Don't export the index column from your DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'./result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
